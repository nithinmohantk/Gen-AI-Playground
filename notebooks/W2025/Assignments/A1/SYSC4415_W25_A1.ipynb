{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jrgreen7/SYSC4906/blob/master/W2025/Assignments/A1/SYSC4415_W25_A1.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Setup for local Running if you are not using Google Colab\n",
    "\n",
    "Install [Anaconda distribution] (https://docs.anaconda.com/anaconda/install/)\n",
    "\n",
    "If you don't have Python on your computer, you can use the [Anaconda Python distribution](http://continuum.io/downloads) to install most of the Python packages you need. Anaconda provides a simple double-click installer for your convenience.\n",
    "\n",
    "This notebook uses several Python packages that come standard with the Anaconda Python distribution. The primary libraries that we'll be using are:\n",
    "\n",
    "* **NumPy**: Provides a fast numerical array structure and helper functions.\n",
    "* **pandas**: Provides a DataFrame structure to store data in memory and work with it easily and efficiently.\n",
    "* **scikit-learn/sklearn**: The essential Machine Learning package in Python.\n",
    "* **matplotlib**: Basic plotting library in Python; most other Python plotting libraries are built on top of it.\n",
    "* **Seaborn**: Advanced statistical plotting library.\n",
    "* **waterqmark**: A Jupyter Notebook extension for printing timestamps, version numbers, and hardware information.\n",
    "\n",
    "To make sure you have all of the packages you need, install them with `conda`:\n",
    "\n",
    "```\n",
    "conda create -n SYSC4415_tutorials python=3.11\n",
    "conda activate SYSC4415_tutorials\n",
    "\n",
    "conda install jupyter\n",
    "conda install numpy pandas scikit-learn matplotlib seaborn graphviz statsmodels\n",
    "conda install -c conda-forge watermark\n",
    "\n",
    "```\n",
    "\n",
    "`conda` may ask you to update some of them if you don't have the most recent version. Allow it to do so.\n",
    "\n",
    "## NOTE about Signature in Google Colab:\n",
    "\n",
    "Use `!pip install watermark` in Google Colab if you have errors while signing your notebook. If you work locally and follow the instructions above in the correct order, it should be already installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions:\n",
    "\n",
    "Please print out values when asked using Python's print() function with f-strings where possible.\n",
    "\n",
    "Submit your saved notebook with all the outputs to Brightspace, but make sure that it will produce correct outputs upon restarting and click \"runtime\" → \"run all\" with clean outputs. Ensure your notebook displays all answers when this is clicked.\n",
    "\n",
    "## Your Submission MUST contain your signature at the bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: \n",
    "# Student Number: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Gradients (4 marks)\n",
    "Hint: use attached PDF if you get lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1a (1 mark)\n",
    "- Manually derive and calculate the gradient of the function: f(x,y,z) = e^(x²) + y^y + e^(xy) + zcos(x) at point (0,1, 1)\n",
    "- Show each component of the gradient.\n",
    "\n",
    "Print your answer using print() function showing all three partial derivatives.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1b (1 mark)\n",
    "For each component of the gradient calculated in Q1a:\n",
    "- Explain what the value means geometrically\n",
    "- Provide a conclusion about each term and gradient in general\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1c (2 marks)\n",
    "Write a Python function to verify your gradient calculation numerically:\n",
    "1. Implement the function f(x,y,z)\n",
    "2. Calculate numerical approximations of partial derivatives using small perturbations\n",
    "3. Compare your analytical results from Q1a with numerical approximations\n",
    "4. Report the result of function evaluation at the point (0,1,1)\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Analysis (8 marks)\n",
    "\n",
    "This section uses the Palmer Penguins dataset, which contains measurements from three penguin species.\n",
    "The dataset includes physical measurements like bill length, bill depth, flipper length, and body mass. We are building a penguin classifier. First we need to assess out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2a (1 mark)\n",
    "✅ Load the Palmer Penguins dataset using Seaborn's load_dataset (provided)\n",
    "- Show that it contains valid data\n",
    "- Create variables for numerical features and labels\n",
    "- Perform basic statistical analysis by printing the general statistics table as in Tutorials. \n",
    "- Find missing values and drop records with missing values for any feature\n",
    "- Save entries with missing values for \"sex\" in a separate variable, we'll use it later.\n",
    "\"\"\"\n",
    "\n",
    "# Load data\n",
    "penguins = sb.load_dataset(\"penguins\")\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2b (2 marks)\n",
    "Create visualizations showing:\n",
    "- Create scatterplot matrix for visual assessment of data\n",
    "- Identify one feature with outliers and show distribution values for two classes (2 histograms).\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2c (1 mark)\n",
    "Analyze class distribution and discuss implications for model training:\n",
    "- Calculate and visualize class proportions\n",
    "- Identify any class imbalance\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Model Development (8 marks)\n",
    "After polishing thedata, let's make our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q3a (2 marks)\n",
    "Preprocess the data:\n",
    "- Use the clean dataset from Q2a (with missing values removed)\n",
    "- Split into training (80%) and test (20%) sets using random_state=42\n",
    "- Print first 5 rows of training data with their species labels\n",
    "- Print shapes of both datasets\n",
    "- Show number of samples per species in each split\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q3b (3 marks)\n",
    "Train and evaluate a Decision Tree:\n",
    "1. Create a Decision Tree with default parameters (random_state=42)\n",
    "2. Evaluate the model:\n",
    "   - Fit on training data (numerical features only)\n",
    "   - Print training and test accuracy score for this tree\n",
    "   - Perform 10-fold cross-validation\n",
    "   - Print mean and std of cross-validation scores and build cv_scores histogram. \n",
    "   - What does the histogram show?\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q3c (3 marks)\n",
    "Analyze the best model from grid search:\n",
    "- Initialize parameter_grid, cross_validation using StratifiedKFold\n",
    "- Identify the best parameters for the tree and show the grid heatmap (don't forget labels)\n",
    "- Plot the best tree structure using graphviz, use max_depth=2 (for better display)\n",
    "\n",
    "Note: when using export_graphviz set out_file=None and use display(graph) function call, where \n",
    "graph is your variable instantiated with Source(dot_data)   \n",
    "Export_graphviz Documentation: https://scikit-learn.org/1.5/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\"\"\"\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "\n",
    "# YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Missing_Sex Prediction (4 marks)\n",
    "In this part of the assignment, we are building a model to infer the missing values from the original dataset to fix the broken records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q4a (2 marks)\n",
    "Prepare data for sex prediction:\n",
    "- Use the clean dataset (no missing values) from Section 2\n",
    "- Convert species to numeric values.\n",
    "\n",
    "Note: Unlike the example in the tutorial, we will use a more straightforward method, LabelEncoder().\n",
    "\n",
    "For this task, you just need to instantiate it, use the fit_transform method on the \"species\" column,\n",
    "and reassign or add the column. \n",
    "See documentation for details:\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "- Create new feature/label split using \"sex\" as target\n",
    "- Scale features using StandardScaler().fit_transform(features) as in Tutorial\n",
    "See documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "- Split data into training (80%) and test (20%) sets\n",
    "- Train these classifiers:\n",
    "  * Logistic Regression (solver='lbfgs')\n",
    "  * Decision Tree (max_depth=3)\n",
    "  * KNN (n_neighbors=5)\n",
    "  * SVM (kernel=\"linear\", C=0.025)\n",
    "- Compare models using (Providing values for each would be enough):\n",
    "  * Training and test accuracy\n",
    "  * 10-fold cross-validation scores\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Prepare features including species as numeric\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q4b (2 marks)\n",
    "Use best model to predict missing sex:\n",
    "- Make sure to create new variable for subset to work with and copy your variable with missing records into it,\n",
    "using new_var = your_variable.copy().\n",
    "- Print records with missing sex values from section 2.\n",
    "- Remove records that have missing values other than sex using dropna: df.dropna(subset=['column_name'],inplace=True).\n",
    "- Scale features using StandardScaler().fit_transform(features) as in Q3\n",
    "- Create new features/labels variables for the new dataset. \n",
    "\n",
    "- Select best classifier based on test performance from Q4a\n",
    "\n",
    "- For each record in missing_sex dataset, using best_model.predict(features) and best_model.predict_proba(features)\n",
    "- Add missing values to the clean dataset and make sure there are no missing values.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratulations! What you just did is called **model-based multiple imputation**. It is one of the methods used to treat missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signature:\n",
    "Don't forget to insert your name and student number and execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your Signarure:\n",
    "%load_ext watermark\n",
    "%watermark -a 'Your Name, #Student_Number' -nmv --packages numpy,pandas,sklearn,matplotlib,seaborn,graphviz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
